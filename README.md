# TensorEase

**TensorEase** is a simple, lightweight deep learning library built from scratch to provide a foundational understanding of deep learning concepts. Itâ€™s designed to be an educational tool for learning how neural networks and backpropagation work at a low level, without relying on existing frameworks.

## Features

- **Basic Layers**: Implementations of fundamental neural network layers, including:
  - `Linear`: A fully connected linear layer.
  
- **Activation Functions**: Essential activation functions such as:
  - `ReLU`: Rectified Linear Unit.

- **Loss Functions**: Basic loss functions for training neural networks, including:
  - `Mean Squared Error (MSE)`: Commonly used in regression tasks.

- **Optimizers**: Simple gradient-based optimizers like:
  - `Stochastic Gradient Descent (SGD)`: A straightforward optimizer for updating model parameters.

## Purpose

TensorEase is intended for students and developers who want to:
- Gain a deeper understanding of how deep learning frameworks operate under the hood.
- Experiment with building and training neural networks from scratch.
- Develop foundational knowledge before moving on to more complex frameworks like TensorFlow or PyTorch.

## Getting Started

TensorEase is currently in development and is being expanded with more layers, activation functions, and optimizers. For now, it serves as a basic tool to experiment with simple neural network architectures, particularly for regression tasks.

## Future Plans

- **Additional Layers**: Expand the library with more types of layers, including convolutional layers and recurrent layers.
- **Advanced Optimizers**: Implement more sophisticated optimization algorithms such as Adam and RMSprop.
- **Dataset Integration**: Provide utilities for loading and preprocessing popular datasets like MNIST.
- **Comprehensive Examples**: Add more example scripts demonstrating the use of TensorEase in various machine learning tasks.

## Contribution

TensorEase is a personal educational project, and contributions are welcome! Feel free to fork the repository, make improvements, and submit pull requests.

## License

This project is licensed under the MIT License.